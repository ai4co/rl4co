# @package _global_

defaults:
  - override /model: am-ppo.yaml
  - override /env: tsp.yaml
  - override /callbacks: default.yaml
  - override /trainer: default.yaml
  - override /logger: wandb.yaml

env:
  generator_params:
    num_loc: 50

logger:
  wandb:
    project: "rl4co"
    tags: ["am-ppo", "${env.name}"]
    group: ${env.name}${env.generator_params.num_loc}
    name: ppo-${env.name}${env.generator_params.num_loc}


model:
  batch_size: 512
  val_batch_size: 1024
  test_batch_size: 1024
  train_data_size: 1_280_000
  val_data_size: 10_000
  test_data_size: 10_000
  clip_range: 0.2
  ppo_epochs: 2
  mini_batch_size: 512
  vf_lambda: 0.5
  entropy_lambda: 0.01
  normalize_adv: False
  max_grad_norm: 0.5
  optimizer_kwargs:
    lr: 1e-4
    weight_decay: 1e-6
  lr_scheduler:
    "MultiStepLR"
  lr_scheduler_kwargs:
    milestones: [80, 95]
    gamma: 0.1

trainer:
  max_epochs: 100
  gradient_clip_val: Null # not supported in manual optimization
  precision: "32-true" # NOTE: this seems to be important during manual optimization

seed: 1234


